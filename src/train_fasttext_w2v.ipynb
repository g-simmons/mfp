{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models import FastText, Word2Vec2Vec\n",
    "from epochlogger import EpochLogger\n",
    "from sentencegenerator import SentenceGenerator\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the shuffled diary entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/mfp-diaries-shuffled.tsv',sep='\\t',header=None,chunksize=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the corpus with each sentence corresponding to an individual food name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# with open(\"../data/foods_as_sentences_retry.txt\", \"a\",encoding='utf-8') as sentences:\n",
    "#     for chunk in data:\n",
    "#         for row in chunk.iterrows():\n",
    "#             ex_diary = json.loads(row[1][2])\n",
    "#             for meal in ex_diary:\n",
    "#                 dish_list = []\n",
    "#                 for dish in meal['dishes']:\n",
    "#                     if dish['name'][0:20] == 'Quick Added Calories':\n",
    "#                         provider = 'Quick Added Calories'\n",
    "#                         item = 'Quick Added Calories'\n",
    "#                     else:\n",
    "#                         name, quant = dish['name'].split(',',maxsplit=1)\n",
    "#                         try:\n",
    "#                             provider, item = name.split(' - ')[0:2]\n",
    "#                         except ValueError:\n",
    "#                             if len(name.split(' - ')) ==1:\n",
    "#                                 provider = name\n",
    "#                                 item = \"\"\n",
    "#                 sentence = provider + ' ' + item\n",
    "#                 sentences.write(sentence+'\\n')\n",
    "#             i += 1\n",
    "#             print(i,end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587187\r"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "with open(\"../data/foods_as_sentences_lower_w2v.txt\", \"a\",encoding='utf-8') as sentences:\n",
    "    for chunk in data:\n",
    "        for row in chunk.iterrows():\n",
    "            ex_diary = json.loads(row[1][2])\n",
    "            for meal in ex_diary:\n",
    "                for dish in meal['dishes']:\n",
    "                    if dish['name'][0:20] == 'Quick Added Calories':\n",
    "                        name = 'Quick Added Calories'\n",
    "                    else:\n",
    "                        name, quant = dish['name'].split(',',maxsplit=1)\n",
    "                        tokens = re.split(\"[, \\-!?*+()012345678~9&%=/\\\"#.>^<:]+\",name)\n",
    "                        tokens_lower =  [token.lower() for token in tokens if len(token) > 2]\n",
    "                    sentence = ' '.join(tokens_lower)\n",
    "                    sentences.write(sentence+'\\n')\n",
    "            i += 1\n",
    "            print(i,end='\\r')\n",
    "sentences.close()\n",
    "total_ex = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587187\r"
     ]
    }
   ],
   "source": [
    "# i = 0\n",
    "# with open(\"../data/meals_as_sentences_lower.txt\", \"w\",encoding='utf-8') as sentences:\n",
    "#     for chunk in data:\n",
    "#         for row in chunk.iterrows():\n",
    "#             ex_diary = json.loads(row[1][2])\n",
    "#             for meal in ex_diary:\n",
    "#                 meal_sentence = ''\n",
    "#                 for dish in meal['dishes']:\n",
    "#                     if dish['name'][0:20] == 'Quick Added Calories':\n",
    "#                         name = 'Quick Added Calories'\n",
    "#                     else:\n",
    "#                         name, quant = dish['name'].split(',',maxsplit=1)\n",
    "#                         tokens = re.split(\"[, \\-!?*+()012345678~9&%=/\\\"#.>^<:]+\",name)\n",
    "#                         tokens_lower =  [token.lower() for token in tokens if len(token) > 2]\n",
    "#                     food_name = ' '.join(tokens_lower)\n",
    "#                     meal_sentence += (food_name + ' ')\n",
    "#                 sentences.write(meal_sentence+'\\n')\n",
    "#             i += 1\n",
    "#             print(i,end='\\r')\n",
    "# sentences.close()\n",
    "# total_ex = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = SentenceGenerator('../data/meals_as_sentences_lower.txt')\n",
    "model = FastText(sentences,min_count=10,window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = SentenceGenerator('../data/foods_as_sentences_lower_w2v.txt')\n",
    "model = Word2Vec(sentences,min_count=10,window=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"../fasttextmodels/foods_w2v_window6_mc10.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rasberry', 0.8593851923942566),\n",
       " ('strawberry', 0.6730685830116272),\n",
       " ('blueberry', 0.6401907801628113),\n",
       " ('cherry', 0.6177578568458557),\n",
       " ('blackberry', 0.613835334777832),\n",
       " ('peach', 0.555031418800354),\n",
       " ('berry', 0.5057841539382935),\n",
       " ('pomegranate', 0.4807957112789154),\n",
       " ('stawberry', 0.47010713815689087),\n",
       " ('apricot', 0.45199546217918396)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('raspberry')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
